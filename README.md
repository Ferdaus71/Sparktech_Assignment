# Duplicate Question Detection  
A Machine Learning + Deep Learning project to classify whether two questions are **duplicate** (semantically similar) or **not duplicate**.  
This project follows a full pipeline from **EDA â†’ Preprocessing â†’ Model â†’ Evaluation â†’ Tuning**.
  
Train File Example Path (Colab Upload):  
`/content/train.csv`

---

# ğŸ“Œ Project Workflow (Step-by-Step)

This project is divided into **5 Steps**, each with clear tasks.

---

# ğŸŸ¦ **STEP 1 â€” Exploratory Data Analysis (EDA)**  
### âœ”ï¸ Start Step 1

### ğŸ”¹ Tasks:
- Visualize distribution of `is_duplicate`
- Check for missing values
- Analyze text:  
  - Word counts  
  - Character counts  
  - Common words  
  - WordCloud  
- Detect outliers/imbalances

### ğŸ”¹ Output:
- Understanding dataset shape  
- Duplicate vs Non-Duplicate percentages  
- Text statistics  
- WordCloud visualization  

### âœ”ï¸ End Step 1

---

# ğŸŸ© **STEP 2 â€” Text Preprocessing**

### âœ”ï¸ Start Step 2

### ğŸ”¹ Tasks:
- Lowercasing  
- Removing stopwords  
- Removing punctuation & special characters  
- Lemmatization  
- Tokenization  
- Convert to numerical features using:
  - TF-IDF  
  - OR Embeddings (optional: Word2Vec, GloVe)

### ğŸ”¹ Output:
- Cleaned & transformed text  
- Numerical vector dataset ready for ML/DL models

### âœ”ï¸ End Step 2

---

# ğŸŸ¥ **STEP 3 â€” Model Creation**

### âœ”ï¸ Start Step 3

### ğŸ”¹ Models Used:
1. **Baseline Machine Learning Models**
   - Logistic Regression  
   - SVM  

2. **Neural Network Models**
   - Custom ANN  
   - LSTM  
   - GRU  
   - Siamese Network (optional)  

3. **Transfer Learning (Optional)**
   - BERT  
   - DistilBERT  

### ğŸ”¹ Output:
- Multiple trained models  
- Neural network for deeper semantic understanding  

### âœ”ï¸ End Step 3

---

# ğŸŸ§ **STEP 4 â€” Model Evaluation**

### âœ”ï¸ Start Step 4

### ğŸ”¹ Metrics:
- Accuracy  
- Precision  
- Recall  
- F1 Score  
- Confusion Matrix  
- ROC Curve + AUC  

### ğŸ”¹ Output:
- Full evaluation charts  
- Performance comparison between models  

### âœ”ï¸ End Step 4

---

# ğŸŸª **STEP 5 â€” Model Tuning (Hyperparameter Optimization)**

### âœ”ï¸ Start Step 5

### ğŸ”¹ Tuning Performed:
- Activation functions tested: ReLU, Sigmoid, Tanh  
- Optimizers: Adam, RMSprop, SGD  
- Learning Rate tuning  
- Batch size tuning  
- Number of epochs  
- Random search  
- Grid search  
- Best model selected after tuning  

### ğŸ”¹ Output:
- Final optimized model  
- Better accuracy & stable performance  

### âœ”ï¸ End Step 5

---

# ğŸ“ Project Structure  
